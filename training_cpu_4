
The following have been reloaded with a version change:
  1) python/3.7.6 => python/3.8.5

epoch 0
torch.Size([512, 50])
cpu
cpu
cpu 

minibatch 0
loss =  1.0689778327941895
two parameters  0.02871917188167572 -0.035590559244155884
minibatch 1
loss =  0.547592043876648
two parameters  -0.22015757858753204 -0.2855897545814514
minibatch 2
loss =  0.5496242046356201
two parameters  -0.05193047225475311 -0.4514385461807251
minibatch 3
loss =  0.549284040927887
two parameters  0.11113028228282928 -0.5773760080337524
minibatch 4
loss =  0.5565367341041565
two parameters  0.16728165745735168 -0.6778992414474487
minibatch 5
loss =  0.5481938123703003
two parameters  0.13163049519062042 -0.7599567174911499
minibatch 6
loss =  0.5466282367706299
two parameters  0.05146130174398422 -0.8275595307350159
minibatch 7
loss =  0.5510445237159729
two parameters  -0.03719758987426758 -0.8833029270172119
minibatch 8
loss =  0.5438618659973145
two parameters  -0.10116048157215118 -0.9290030598640442
minibatch 9
loss =  0.5487483143806458
two parameters  -0.12031295150518417 -0.9660068154335022
minibatch 10
loss =  0.5299621224403381
two parameters  -0.09719720482826233 -0.9953590631484985
minibatch 11
loss =  0.5499399304389954
two parameters  -0.04659373313188553 -1.0179004669189453
minibatch 12
loss =  0.5387757420539856
two parameters  0.013101518154144287 -1.034327745437622
minibatch 13
loss =  0.5510041117668152
two parameters  0.06279373914003372 -1.0452326536178589
minibatch 14
loss =  0.5510368347167969
two parameters  0.08767993748188019 -1.0511285066604614
minibatch 15
loss =  0.5462434887886047
two parameters  0.08304838091135025 -1.0524686574935913
minibatch 16
loss =  0.5421047806739807
two parameters  0.054094430059194565 -1.049659252166748
minibatch 17
loss =  0.5330666303634644
two parameters  0.011880885809659958 -1.043068766593933
minibatch 18
loss =  0.5420525074005127
two parameters  -0.030020661652088165 -1.033035159111023
minibatch 19
loss =  0.5374962687492371
two parameters  -0.058884039521217346 -1.0198708772659302
minibatch 20
loss =  0.5677449703216553
two parameters  -0.06698153913021088 -1.0038670301437378
minibatch 21
loss =  0.5404775142669678
two parameters  -0.060464296489953995 -0.9945817589759827
minibatch 22
loss =  0.5530573725700378
two parameters  -0.045415978878736496 -0.9841228723526001
minibatch 23
loss =  0.5502275228500366
two parameters  -0.024858346208930016 -0.9725920557975769
minibatch 24
loss =  0.5405231714248657
two parameters  -0.002334045246243477 -0.9600838422775269
minibatch 25
loss =  0.5459213256835938
two parameters  0.01854671537876129 -0.9466864466667175
minibatch 26
loss =  0.5533818006515503
two parameters  0.03462354838848114 -0.9324824810028076
minibatch 27
loss =  0.5403169989585876
two parameters  0.0437086746096611 -0.9175494313240051
minibatch 28
loss =  0.5441945791244507
two parameters  0.04493275657296181 -0.9019601941108704
minibatch 29
loss =  0.5496233701705933
two parameters  0.03878503665328026 -0.8857833743095398
minibatch 30
loss =  0.5638396143913269
two parameters  0.02689002826809883 -0.8690837621688843
minibatch 31
loss =  0.5478231310844421
two parameters  0.011649256572127342 -0.8519224524497986
minibatch 32
loss =  0.5370139479637146
two parameters  -0.0041695646941661835 -0.8343572616577148
minibatch 33
loss =  0.5433516502380371
two parameters  -0.017876114696264267 -0.8164427876472473
minibatch 34
loss =  0.5421888828277588
two parameters  -0.027304254472255707 -0.7982307076454163
minibatch 35
loss =  0.552782416343689
two parameters  -0.031175456941127777 -0.7797698974609375
minibatch 36
loss =  0.5575678944587708
two parameters  -0.02927732653915882 -0.7611066102981567
minibatch 37
loss =  0.5517698526382446
two parameters  -0.022420097142457962 -0.7422845959663391
minibatch 38
loss =  0.5583798289299011
two parameters  -0.012214494869112968 -0.723345160484314
minibatch 39
loss =  0.5609455108642578
two parameters  -0.0007408689707517624 -0.7043274641036987
minibatch 40
loss =  0.5535867810249329
two parameters  0.009836096316576004 -0.6852683424949646
minibatch 41
loss =  0.5326926708221436
two parameters  0.013747258111834526 -0.6757354736328125
minibatch 42
loss =  0.534313976764679
two parameters  0.016032766550779343 -0.6662036180496216
minibatch 43
loss =  0.5439491868019104
two parameters  0.01661268062889576 -0.6566770076751709
minibatch 44
loss =  0.5544280409812927
two parameters  0.01557218562811613 -0.6471598148345947
minibatch 45
loss =  0.5456469655036926
two parameters  0.013142457231879234 -0.6376560926437378
minibatch 46
loss =  0.5430524349212646
two parameters  0.009669046849012375 -0.6281697154045105
minibatch 47
loss =  0.540270984172821
two parameters  0.005571790970861912 -0.6187045574188232
minibatch 48
loss =  0.5600053071975708
two parameters  0.0013002604246139526 -0.6092643737792969
minibatch 49
loss =  0.5539767742156982
two parameters  -0.002711300738155842 -0.5998527407646179
minibatch 50
loss =  0.549084484577179
two parameters  -0.0060855671763420105 -0.5904732346534729
minibatch 51
loss =  0.5542271137237549
two parameters  -0.008536283858120441 -0.581129252910614
minibatch 52
loss =  0.5564672350883484
two parameters  -0.009891539812088013 -0.5718241333961487
minibatch 53
loss =  0.5542126297950745
two parameters  -0.010103940032422543 -0.5625610947608948
minibatch 54
loss =  0.5526492595672607
two parameters  -0.00924714282155037 -0.5533432364463806
minibatch 55
loss =  0.5236141085624695
two parameters  -0.0074999709613621235 -0.5441735982894897
minibatch 56
loss =  0.5454295873641968
two parameters  -0.0051206061616539955 -0.5350551009178162
minibatch 57
loss =  0.5483224391937256
two parameters  -0.002414182061329484 -0.5259904861450195
minibatch 58
loss =  0.5432900786399841
two parameters  0.0003025634214282036 -0.5169825553894043
minibatch 59
loss =  0.5513888001441956
two parameters  0.0027358250226825476 -0.508033812046051
minibatch 60
loss =  0.5626398324966431
two parameters  0.004644880071282387 -0.49914681911468506
minibatch 61
loss =  0.5342970490455627
two parameters  0.005254814866930246 -0.49473538994789124
minibatch 62
loss =  0.5424597263336182
two parameters  0.005515949334949255 -0.4903538227081299
minibatch 63
loss =  0.5547643899917603
two parameters  0.005443578120321035 -0.486000120639801
minibatch 64
loss =  0.5466353297233582
two parameters  0.005070280283689499 -0.4816725552082062
minibatch 65
loss =  0.5484158992767334
two parameters  0.004442885052412748 -0.4773695468902588
minibatch 66
loss =  0.5597555637359619
two parameters  0.0036188375670462847 -0.47308969497680664
minibatch 67
loss =  0.5349692702293396
two parameters  0.0026622069999575615 -0.4688318073749542
minibatch 68
loss =  0.560836911201477
two parameters  0.001639577210880816 -0.4645948112010956
minibatch 69
loss =  0.5446902513504028
two parameters  0.0006160603370517492 -0.4603777825832367
minibatch 70
loss =  0.5452622771263123
two parameters  -0.0003483499167487025 -0.4561798870563507
minibatch 71
loss =  0.551013708114624
two parameters  -0.0012018968118354678 -0.4520004689693451
minibatch 72
loss =  0.5490186214447021
two parameters  -0.001903496216982603 -0.4478389024734497
minibatch 73
loss =  0.5487372875213623
two parameters  -0.0024243853986263275 -0.44369471073150635
minibatch 74
loss =  0.5616341233253479
two parameters  -0.002748930361121893 -0.4395674765110016
minibatch 75
loss =  0.5619640946388245
two parameters  -0.0028745937161147594 -0.43545687198638916
minibatch 76
loss =  0.5482442378997803
two parameters  -0.0028111133724451065 -0.4313626289367676
minibatch 77
loss =  0.5455499887466431
two parameters  -0.0025789933279156685 -0.4272845387458801
minibatch 78
loss =  0.5492253303527832
two parameters  -0.002207439625635743 -0.4232224225997925
minibatch 79
loss =  0.5439149737358093
two parameters  -0.0017319059697911143 -0.41917622089385986
minibatch 80
loss =  0.5516267418861389
two parameters  -0.001191423274576664 -0.4151458442211151
minibatch 81
loss =  0.5453738570213318
two parameters  -0.0009086577920243144 -0.41313856840133667
minibatch 82
loss =  0.5464902520179749
two parameters  -0.0006233957828953862 -0.4111383259296417
minibatch 83
loss =  0.5477973818778992
two parameters  -0.00034491653786972165 -0.4091443419456482
minibatch 84
loss =  0.5514094829559326
two parameters  -8.15187522675842e-05 -0.40715593099594116
minibatch 85
loss =  0.5475219488143921
two parameters  0.00015966453065630049 -0.4051724374294281
minibatch 86
loss =  0.5446032881736755
two parameters  0.00037280190736055374 -0.40319332480430603
minibatch 87
loss =  0.5536132454872131
two parameters  0.0005534486845135689 -0.40121811628341675
minibatch 88
loss =  0.552808940410614
two parameters  0.0006985815125517547 -0.39924636483192444
minibatch 89
loss =  0.5420581102371216
two parameters  0.0008065857691690326 -0.39727771282196045
minibatch 90
loss =  0.5387030243873596
two parameters  0.0008771981229074299 -0.39531180262565613
minibatch 91
loss =  0.5459151268005371
two parameters  0.0009114093263633549 -0.39334836602211
minibatch 92
loss =  0.5513051748275757
two parameters  0.0009113336564041674 -0.39138713479042053
minibatch 93
loss =  0.5522683262825012
two parameters  0.0008800505311228335 -0.38942793011665344
minibatch 94
loss =  0.5505077838897705
two parameters  0.0008214262197725475 -0.387470543384552
minibatch 95
loss =  0.5380004048347473
two parameters  0.0007399225723929703 -0.3855148255825043
minibatch 96
loss =  0.5533171892166138
two parameters  0.000640399637632072 -0.3835606276988983
minibatch 97
loss =  0.5484296679496765
two parameters  0.0005279197939671576 -0.38160786032676697
minibatch 98
loss =  0.5435471534729004
two parameters  0.00040755956433713436 -0.37965646386146545
minibatch 99
loss =  0.5582795143127441
two parameters  0.0002842348185367882 -0.3777063488960266
minibatch 100
loss =  0.5471376180648804
two parameters  0.00016254474758170545 -0.37575748562812805
minibatch 101
loss =  0.5445180535316467
two parameters  0.00010459142504259944 -0.3747836649417877
minibatch 102
loss =  0.541910707950592
two parameters  5.02833972859662e-05 -0.37381020188331604
minibatch 103
loss =  0.5423502326011658
two parameters  2.469423634465784e-07 -0.3728368878364563
minibatch 104
loss =  0.5609773993492126
two parameters  -4.501932562561706e-05 -0.3718635141849518
minibatch 105
loss =  0.534833550453186
two parameters  -8.514265937265009e-05 -0.37088990211486816
minibatch 106
loss =  0.5505856275558472
two parameters  -0.0001198724057758227 -0.3699159324169159
minibatch 107
loss =  0.5334054231643677
two parameters  -0.0001490744762122631 -0.36894142627716064
minibatch 108
loss =  0.5331093668937683
two parameters  -0.00017272414697799832 -0.36796629428863525
minibatch 109
loss =  0.5467351675033569
two parameters  -0.00019089765555690974 -0.36699041724205017
