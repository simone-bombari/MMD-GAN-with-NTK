ucx/1.7.0 on Debian 10(buster) does not support Cuda, yet 
ucx/1.7.0 on Debian 10(buster) does not support Cuda, yet 
ucx/1.7.0 on Debian 10(buster) does not support Cuda, yet 

The following have been reloaded with a version change:
  1) python/3.7.6 => python/3.8.5

Thu Apr  1 10:55:46 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.39       Driver Version: 460.39       CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  GeForce GTX 980     Off  | 00000000:02:00.0 Off |                  N/A |
| 34%   28C    P8    11W / 180W |     14MiB /  4043MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX 980     Off  | 00000000:03:00.0 Off |                  N/A |
| 35%   27C    P8    11W / 180W |      2MiB /  4043MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  GeForce GTX 980     Off  | 00000000:82:00.0 Off |                  N/A |
| 26%   26C    P8    12W / 180W |      2MiB /  4043MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  GeForce GTX 980     Off  | 00000000:83:00.0 Off |                  N/A |
| 26%   26C    P8    13W / 180W |      2MiB /  4043MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1855      G   /usr/lib/xorg/Xorg                 11MiB |
+-----------------------------------------------------------------------------+
epoch 0
cuda:0
cuda:0
cuda:0 

minibatch 0
loss =  tensor(1.1359, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 1
loss =  tensor(1.1292, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 2
loss =  tensor(1.1066, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 3
loss =  tensor(1.0803, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 4
loss =  tensor(1.0430, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 5
loss =  tensor(0.9963, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 6
loss =  tensor(0.9582, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 7
loss =  tensor(0.9469, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 8
loss =  tensor(0.9465, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 9
loss =  tensor(0.9495, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 10
loss =  tensor(0.9535, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 11
loss =  tensor(0.9545, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 12
loss =  tensor(0.9572, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 13
loss =  tensor(0.9577, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 14
loss =  tensor(0.9557, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 15
loss =  tensor(0.9571, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 16
loss =  tensor(0.9564, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 17
loss =  tensor(0.9577, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 18
loss =  tensor(0.9535, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 19
loss =  tensor(0.9540, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 20
loss =  tensor(0.9500, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 21
loss =  tensor(0.9477, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 22
loss =  tensor(0.9396, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 23
loss =  tensor(0.9304, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 24
loss =  tensor(0.9165, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 25
loss =  tensor(0.9002, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 26
loss =  tensor(0.8979, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 27
loss =  tensor(0.9034, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 28
loss =  tensor(0.9014, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 29
loss =  tensor(0.8886, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 30
loss =  tensor(0.8840, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 31
loss =  tensor(0.8794, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 32
loss =  tensor(0.8738, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 33
loss =  tensor(0.8690, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 34
loss =  tensor(0.8617, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 35
loss =  tensor(0.8511, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 36
loss =  tensor(0.8418, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 37
loss =  tensor(0.8405, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 38
loss =  tensor(0.8353, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 39
loss =  tensor(0.8280, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 40
loss =  tensor(0.8225, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 41
loss =  tensor(0.8174, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 42
loss =  tensor(0.8124, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 43
loss =  tensor(0.7986, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 44
loss =  tensor(0.7900, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 45
loss =  tensor(0.7809, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 46
loss =  tensor(0.7677, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 47
loss =  tensor(0.7609, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 48
loss =  tensor(0.7491, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 49
loss =  tensor(0.7422, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 50
loss =  tensor(0.7352, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 51
loss =  tensor(0.7299, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 52
loss =  tensor(0.7270, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 53
loss =  tensor(0.7213, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 54
loss =  tensor(0.7182, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 55
loss =  tensor(0.7163, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 56
loss =  tensor(0.7146, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 57
loss =  tensor(0.7130, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 58
loss =  tensor(0.7097, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 59
loss =  tensor(0.7118, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 60
loss =  tensor(0.7090, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 61
loss =  tensor(0.7079, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 62
loss =  tensor(0.7047, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 63
loss =  tensor(0.7019, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 64
loss =  tensor(0.7031, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 65
loss =  tensor(0.7009, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 66
loss =  tensor(0.6989, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 67
loss =  tensor(0.6957, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 68
loss =  tensor(0.6941, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 69
loss =  tensor(0.6917, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 70
loss =  tensor(0.6942, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 71
loss =  tensor(0.6833, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 72
loss =  tensor(0.6882, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 73
loss =  tensor(0.6898, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 74
loss =  tensor(0.6875, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 75
loss =  tensor(0.6857, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 76
loss =  tensor(0.6833, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 77
loss =  tensor(0.6800, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 78
loss =  tensor(0.6782, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 79
loss =  tensor(0.6782, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 80
loss =  tensor(0.6777, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 81
loss =  tensor(0.6815, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 82
loss =  tensor(0.6757, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 83
loss =  tensor(0.6770, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 84
loss =  tensor(0.6764, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 85
loss =  tensor(0.6751, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 86
loss =  tensor(0.6748, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 87
loss =  tensor(0.6699, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 88
loss =  tensor(0.6732, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 89
loss =  tensor(0.6740, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 90
loss =  tensor(0.6751, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 91
loss =  tensor(0.6710, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 92
loss =  tensor(0.6720, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 93
loss =  tensor(0.6707, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 94
loss =  tensor(0.6706, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 95
loss =  tensor(0.6701, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 96
loss =  tensor(0.6703, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 97
loss =  tensor(0.6685, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 98
loss =  tensor(0.6697, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 99
loss =  tensor(0.6695, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 100
loss =  tensor(0.6706, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 101
loss =  tensor(0.6660, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 102
loss =  tensor(0.6707, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 103
loss =  tensor(0.6691, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 104
loss =  tensor(0.6691, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 105
loss =  tensor(0.6654, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 106
loss =  tensor(0.6686, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 107
loss =  tensor(0.6733, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 108
loss =  tensor(0.6659, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 109
loss =  tensor(0.6679, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 110
loss =  tensor(0.6655, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 111
loss =  tensor(0.6683, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 112
loss =  tensor(0.6695, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 113
loss =  tensor(0.6649, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 114
loss =  tensor(0.6700, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 115
loss =  tensor(0.6689, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 116
loss =  tensor(0.6655, device='cuda:0', grad_fn=<SubBackward0>)
minibatch 117
loss =  tensor(-1.8405, device='cuda:0', grad_fn=<SubBackward0>)
